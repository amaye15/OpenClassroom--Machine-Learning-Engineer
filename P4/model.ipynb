{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "def optimize_kmeans(df, k_range=(2, 10), batch_size=100):\n",
    "    \"\"\"\n",
    "    Apply and optimize K-means clustering on a given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame, data for clustering\n",
    "    - k_range: tuple, range of k values to try (inclusive)\n",
    "    \n",
    "    Returns:\n",
    "    - dict, containing optimal k and metrics\n",
    "    \"\"\"\n",
    "    # Initialize variables to store metrics\n",
    "    k_values = []\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    davies_bouldin_scores = []\n",
    "    \n",
    "    # Loop through different values of k to find the optimal one\n",
    "    for k in range(k_range[0], k_range[1]):\n",
    "        # Fit K-means model\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, batch_size=batch_size, random_state=42, n_init = \"auto\").fit(df)\n",
    "        \n",
    "        # Get cluster labels\n",
    "        labels = kmeans.labels_\n",
    "        \n",
    "        # Calculate metrics\n",
    "        inertia = kmeans.inertia_\n",
    "        silhouette = silhouette_score(df, labels)\n",
    "        davies_bouldin = davies_bouldin_score(df, labels)\n",
    "        \n",
    "        # Store metrics\n",
    "        k_values.append(k)\n",
    "        inertias.append(inertia)\n",
    "        silhouette_scores.append(silhouette)\n",
    "        davies_bouldin_scores.append(davies_bouldin)\n",
    "        \n",
    "    # Finding the optimal k based on metrics\n",
    "    # Lower inertia and Davies-Bouldin score is better. Higher silhouette score is better.\n",
    "    optimal_k = k_values[np.argmin(davies_bouldin_scores)]  # Change this based on the metric you prioritize\n",
    "    \n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'k_values': k_values,\n",
    "        'inertias': inertias,\n",
    "        'silhouette_scores': silhouette_scores,\n",
    "        'davies_bouldin_scores': davies_bouldin_scores,\n",
    "        'optimal_k': optimal_k\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data/olist_sellers_dataset.csv to data/olist_sellers_dataset.csv.gz and deleted the original file.\n",
      "Converted data/product_category_name_translation.csv to data/product_category_name_translation.csv.gz and deleted the original file.\n",
      "Converted data/olist_orders_dataset.csv to data/olist_orders_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_order_items_dataset.csv to data/olist_order_items_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_customers_dataset.csv to data/olist_customers_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_geolocation_dataset.csv to data/olist_geolocation_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_order_payments_dataset.csv to data/olist_order_payments_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_order_reviews_dataset.csv to data/olist_order_reviews_dataset.csv.gz and deleted the original file.\n",
      "Converted data/olist_products_dataset.csv to data/olist_products_dataset.csv.gz and deleted the original file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functions import find_csv_files, load_csvs_to_dict, sort_and_classify_column, transform_to_days\n",
    "\n",
    "DATA_PATH = \"/Users/typhaine/Documents/Doc_Gorilla/OpenClassroom--Machine-Learning-Engineer/P4/data\"\n",
    "\n",
    "csv_files = find_csv_files(DATA_PATH)\n",
    "\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def csv_to_gzip_pandas_and_delete(csv_files: List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Convert a list of CSV files to gzipped files and delete the original CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_files (List[str]): List of paths to the CSV files to be converted.\n",
    "        \n",
    "    Returns:\n",
    "        None: The function performs file operations and does not return any value.\n",
    "    \"\"\"\n",
    "    for csv_file in csv_files:\n",
    "        # Define the gzipped filename based on the original csv filename\n",
    "        gzip_file = f\"{csv_file}.gz\"\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Write the DataFrame to a GZIP file\n",
    "        df.to_csv(gzip_file, compression='gzip', index=False)\n",
    "        \n",
    "        # Delete the original CSV file\n",
    "        os.remove(csv_file)\n",
    "        \n",
    "        print(f\"Converted {csv_file} to {gzip_file} and deleted the original file.\")\n",
    "    return\n",
    "\n",
    "# Example usage:\n",
    "#csv_files = ['file1.csv', 'file2.csv']\n",
    "csv_to_gzip_pandas_and_delete(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tmp_df.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimize_kmeans(df.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
