{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Utilisation de Techniques de Réduction de Dimension\n",
    "Utiliser des techniques appropriées de réduction en deux dimensions de données de grande dimension et les représenter graphiquement afin d'en réaliser l'analyse exploratoire.\n",
    "\n",
    "### CE1: Mise en Œuvre de la Réduction de Dimension\n",
    "- Vous avez mis en œuvre au moins une technique de réduction de dimension (via LDA, ACP, T-SNE, UMAP ou autre technique).\n",
    "\n",
    "### CE2: Représentation Graphique en 2D\n",
    "- Vous avez réalisé au moins un graphique représentant les données réduites en 2D (par exemple via LDAvis pour les Topics).\n",
    "\n",
    "### CE3: Analyse du Graphique en 2D\n",
    "- Vous avez réalisé et formalisé une analyse du graphique en 2D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement de Données Textuelles\n",
    "Prétraiter des données non structurées de type texte en prenant en compte les normes liées à la propriété intellectuelle et réaliser un feature engineering adapté aux modèles d'apprentissage afin d’obtenir un jeu de données exploitables.\n",
    "\n",
    "### CE1: Nettoyage de Texte\n",
    "- Vous avez nettoyé les champs de texte (suppression de la ponctuation et des mots).\n",
    "\n",
    "### CE2: Tokenisation\n",
    "- Vous avez écrit une fonction permettant de “tokeniser” une phrase.\n",
    "\n",
    "### CE3: Stemming\n",
    "- Vous avez écrit une fonction permettant de “stemmer” une phrase.\n",
    "\n",
    "### CE4: Lemmatisation\n",
    "- Vous avez écrit une fonction permettant de “lemmatiser” une phrase.\n",
    "\n",
    "### CE5: Feature Engineering\n",
    "- Vous avez construit des features (\"feature engineering\") de type bag-of-words (bag-of-words standard : comptage de mots, et Tf-idf), avec des étapes de nettoyage supplémentaires : seuil de fréquence des mots, normalisation des mots.\n",
    "\n",
    "### CE6: Test sur Exemple\n",
    "- Vous avez testé une phrase ou un court texte d'exemple, pour illustrer la bonne réalisation des 5 étapes précédentes.\n",
    "\n",
    "### CE7: Techniques d'Embedding Avancées\n",
    "- Vous avez, en complément de la démarche de type “bag-of-words”, mis en oeuvre 3 démarches de word/sentence embedding : Word2Vec (ou Doc2Vec ou Glove ou FastText), BERT, et USE (Universal Sentence Encoder).\n",
    "\n",
    "### CE8: Respect de la Propriété Intellectuelle\n",
    "- Vous vous êtes assuré que le texte traité ne relève pas d’une propriété intellectuelle dont l’utilisation ou la modification est interdite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/typhaine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/typhaine/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-21 00:27:42</td>\n",
       "      <td>Iterating over dictionaries using &amp;#39;for&amp;#39...</td>\n",
       "      <td>python, dictionary</td>\n",
       "      <td>4235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-10 09:04:49</td>\n",
       "      <td>How to iterate over rows in a DataFrame in Pandas</td>\n",
       "      <td>python, pandas, dataframe, loops</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-24 17:55:08</td>\n",
       "      <td>Catch multiple exceptions in one line (except ...</td>\n",
       "      <td>python, exception</td>\n",
       "      <td>3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-08-09 04:52:50</td>\n",
       "      <td>Does Python have a string &amp;#39;contains&amp;#39; s...</td>\n",
       "      <td>python, string, substring, contains</td>\n",
       "      <td>3587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-08 21:31:22</td>\n",
       "      <td>How do I list all files of a directory?</td>\n",
       "      <td>python, directory</td>\n",
       "      <td>3466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2014-04-25 15:31:47</td>\n",
       "      <td>Asking the user for input until they give a va...</td>\n",
       "      <td>python, validation, input</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2011-04-15 14:22:01</td>\n",
       "      <td>How can I fill out a Python string with spaces?</td>\n",
       "      <td>python, string, string-formatting, padding</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2010-12-14 02:41:29</td>\n",
       "      <td>How do I append one string to another in Python?</td>\n",
       "      <td>python, string, append</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2015-05-01 04:25:16</td>\n",
       "      <td>Where does pip install its packages?</td>\n",
       "      <td>python, django, pip, virtualenv</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2016-10-11 16:59:23</td>\n",
       "      <td>Are dictionaries ordered in Python 3.6+?</td>\n",
       "      <td>python, python-3.x, dictionary, python-interna...</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                              Title  \\\n",
       "0    2010-07-21 00:27:42  Iterating over dictionaries using &#39;for&#39...   \n",
       "1    2013-05-10 09:04:49  How to iterate over rows in a DataFrame in Pandas   \n",
       "2    2011-06-24 17:55:08  Catch multiple exceptions in one line (except ...   \n",
       "3    2010-08-09 04:52:50  Does Python have a string &#39;contains&#39; s...   \n",
       "4    2010-07-08 21:31:22            How do I list all files of a directory?   \n",
       "..                   ...                                                ...   \n",
       "245  2014-04-25 15:31:47  Asking the user for input until they give a va...   \n",
       "246  2011-04-15 14:22:01    How can I fill out a Python string with spaces?   \n",
       "247  2010-12-14 02:41:29   How do I append one string to another in Python?   \n",
       "248  2015-05-01 04:25:16               Where does pip install its packages?   \n",
       "249  2016-10-11 16:59:23           Are dictionaries ordered in Python 3.6+?   \n",
       "\n",
       "                                                  Tags  Score  \n",
       "0                                   python, dictionary   4235  \n",
       "1                     python, pandas, dataframe, loops   4000  \n",
       "2                                    python, exception   3783  \n",
       "3                  python, string, substring, contains   3587  \n",
       "4                                    python, directory   3466  \n",
       "..                                                 ...    ...  \n",
       "245                          python, validation, input    750  \n",
       "246         python, string, string-formatting, padding    746  \n",
       "247                             python, string, append    746  \n",
       "248                    python, django, pip, virtualenv    745  \n",
       "249  python, python-3.x, dictionary, python-interna...    740  \n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "DATA_LOAD_FILE = os.path.join(ROOT_PATH, \"data/StackOverFlow.csv.gz\")\n",
    "\n",
    "df = pd.read_csv(DATA_LOAD_FILE)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    stemmer = PorterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in sentence.split()])\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in sentence.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Score</th>\n",
       "      <th>TitleClean</th>\n",
       "      <th>TitleCleanTokenised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-21 00:27:42</td>\n",
       "      <td>Iterating over dictionaries using &amp;#39;for&amp;#39...</td>\n",
       "      <td>python, dictionary</td>\n",
       "      <td>4235</td>\n",
       "      <td>iter over dictionari use 39for39 loop</td>\n",
       "      <td>[iter, over, dictionari, use, 39for39, loop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-10 09:04:49</td>\n",
       "      <td>How to iterate over rows in a DataFrame in Pandas</td>\n",
       "      <td>python, pandas, dataframe, loops</td>\n",
       "      <td>4000</td>\n",
       "      <td>how to iter over row in a datafram in panda</td>\n",
       "      <td>[how, to, iter, over, row, in, a, datafram, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-06-24 17:55:08</td>\n",
       "      <td>Catch multiple exceptions in one line (except ...</td>\n",
       "      <td>python, exception</td>\n",
       "      <td>3783</td>\n",
       "      <td>catch multipl except in one line except block</td>\n",
       "      <td>[catch, multipl, except, in, one, line, except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-08-09 04:52:50</td>\n",
       "      <td>Does Python have a string &amp;#39;contains&amp;#39; s...</td>\n",
       "      <td>python, string, substring, contains</td>\n",
       "      <td>3587</td>\n",
       "      <td>doe python have a string 39contains39 substr m...</td>\n",
       "      <td>[doe, python, have, a, string, 39contains39, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-08 21:31:22</td>\n",
       "      <td>How do I list all files of a directory?</td>\n",
       "      <td>python, directory</td>\n",
       "      <td>3466</td>\n",
       "      <td>how do i list all file of a directori</td>\n",
       "      <td>[how, do, i, list, all, file, of, a, directori]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2014-04-25 15:31:47</td>\n",
       "      <td>Asking the user for input until they give a va...</td>\n",
       "      <td>python, validation, input</td>\n",
       "      <td>750</td>\n",
       "      <td>ask the user for input until they give a valid...</td>\n",
       "      <td>[ask, the, user, for, input, until, they, give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2011-04-15 14:22:01</td>\n",
       "      <td>How can I fill out a Python string with spaces?</td>\n",
       "      <td>python, string, string-formatting, padding</td>\n",
       "      <td>746</td>\n",
       "      <td>how can i fill out a python string with space</td>\n",
       "      <td>[how, can, i, fill, out, a, python, string, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2010-12-14 02:41:29</td>\n",
       "      <td>How do I append one string to another in Python?</td>\n",
       "      <td>python, string, append</td>\n",
       "      <td>746</td>\n",
       "      <td>how do i append one string to anoth in python</td>\n",
       "      <td>[how, do, i, append, one, string, to, anoth, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2015-05-01 04:25:16</td>\n",
       "      <td>Where does pip install its packages?</td>\n",
       "      <td>python, django, pip, virtualenv</td>\n",
       "      <td>745</td>\n",
       "      <td>where doe pip instal it packag</td>\n",
       "      <td>[where, doe, pip, instal, it, packag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2016-10-11 16:59:23</td>\n",
       "      <td>Are dictionaries ordered in Python 3.6+?</td>\n",
       "      <td>python, python-3.x, dictionary, python-interna...</td>\n",
       "      <td>740</td>\n",
       "      <td>are dictionari order in python 36</td>\n",
       "      <td>[are, dictionari, order, in, python, 36]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date                                              Title  \\\n",
       "0    2010-07-21 00:27:42  Iterating over dictionaries using &#39;for&#39...   \n",
       "1    2013-05-10 09:04:49  How to iterate over rows in a DataFrame in Pandas   \n",
       "2    2011-06-24 17:55:08  Catch multiple exceptions in one line (except ...   \n",
       "3    2010-08-09 04:52:50  Does Python have a string &#39;contains&#39; s...   \n",
       "4    2010-07-08 21:31:22            How do I list all files of a directory?   \n",
       "..                   ...                                                ...   \n",
       "245  2014-04-25 15:31:47  Asking the user for input until they give a va...   \n",
       "246  2011-04-15 14:22:01    How can I fill out a Python string with spaces?   \n",
       "247  2010-12-14 02:41:29   How do I append one string to another in Python?   \n",
       "248  2015-05-01 04:25:16               Where does pip install its packages?   \n",
       "249  2016-10-11 16:59:23           Are dictionaries ordered in Python 3.6+?   \n",
       "\n",
       "                                                  Tags  Score  \\\n",
       "0                                   python, dictionary   4235   \n",
       "1                     python, pandas, dataframe, loops   4000   \n",
       "2                                    python, exception   3783   \n",
       "3                  python, string, substring, contains   3587   \n",
       "4                                    python, directory   3466   \n",
       "..                                                 ...    ...   \n",
       "245                          python, validation, input    750   \n",
       "246         python, string, string-formatting, padding    746   \n",
       "247                             python, string, append    746   \n",
       "248                    python, django, pip, virtualenv    745   \n",
       "249  python, python-3.x, dictionary, python-interna...    740   \n",
       "\n",
       "                                            TitleClean  \\\n",
       "0                iter over dictionari use 39for39 loop   \n",
       "1          how to iter over row in a datafram in panda   \n",
       "2        catch multipl except in one line except block   \n",
       "3    doe python have a string 39contains39 substr m...   \n",
       "4                how do i list all file of a directori   \n",
       "..                                                 ...   \n",
       "245  ask the user for input until they give a valid...   \n",
       "246      how can i fill out a python string with space   \n",
       "247      how do i append one string to anoth in python   \n",
       "248                     where doe pip instal it packag   \n",
       "249                  are dictionari order in python 36   \n",
       "\n",
       "                                   TitleCleanTokenised  \n",
       "0         [iter, over, dictionari, use, 39for39, loop]  \n",
       "1    [how, to, iter, over, row, in, a, datafram, in...  \n",
       "2    [catch, multipl, except, in, one, line, except...  \n",
       "3    [doe, python, have, a, string, 39contains39, s...  \n",
       "4      [how, do, i, list, all, file, of, a, directori]  \n",
       "..                                                 ...  \n",
       "245  [ask, the, user, for, input, until, they, give...  \n",
       "246  [how, can, i, fill, out, a, python, string, wi...  \n",
       "247  [how, do, i, append, one, string, to, anoth, i...  \n",
       "248              [where, doe, pip, instal, it, packag]  \n",
       "249           [are, dictionari, order, in, python, 36]  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"TitleClean\"] = df[\"Title\"].apply(clean_text).apply(stem_sentence).apply(lemmatize_sentence)\n",
    "df[\"TitleCleanTokenised\"] = df[\"TitleClean\"].apply(tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=1, lowercase=False)\n",
    "count_vectorized = count_vectorizer.fit_transform(df[\"TitleClean\"])\n",
    "count_dataframe = pd.DataFrame(count_vectorized.toarray(), columns=count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>all</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>anoth</th>\n",
       "      <th>append</th>\n",
       "      <th>are</th>\n",
       "      <th>argpars</th>\n",
       "      <th>argument</th>\n",
       "      <th>array</th>\n",
       "      <th>...</th>\n",
       "      <th>version</th>\n",
       "      <th>virtualenv</th>\n",
       "      <th>way</th>\n",
       "      <th>what</th>\n",
       "      <th>whi</th>\n",
       "      <th>with</th>\n",
       "      <th>without</th>\n",
       "      <th>work</th>\n",
       "      <th>write</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514226</td>\n",
       "      <td>0.465822</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.51491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     after       all   an  and     anoth    append      are  argpars  \\\n",
       "0      0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "1      0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "2      0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "3      0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "4      0.0  0.500384  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "..     ...       ...  ...  ...       ...       ...      ...      ...   \n",
       "245    0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "246    0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "247    0.0  0.000000  0.0  0.0  0.514226  0.465822  0.00000      0.0   \n",
       "248    0.0  0.000000  0.0  0.0  0.000000  0.000000  0.00000      0.0   \n",
       "249    0.0  0.000000  0.0  0.0  0.000000  0.000000  0.51491      0.0   \n",
       "\n",
       "     argument  array  ...  version  virtualenv  way  what  whi      with  \\\n",
       "0         0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "1         0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "2         0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "3         0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "4         0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "..        ...    ...  ...      ...         ...  ...   ...  ...       ...   \n",
       "245       0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "246       0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.389439   \n",
       "247       0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "248       0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "249       0.0    0.0  ...      0.0         0.0  0.0   0.0  0.0  0.000000   \n",
       "\n",
       "     without  work  write  you  \n",
       "0        0.0   0.0    0.0  0.0  \n",
       "1        0.0   0.0    0.0  0.0  \n",
       "2        0.0   0.0    0.0  0.0  \n",
       "3        0.0   0.0    0.0  0.0  \n",
       "4        0.0   0.0    0.0  0.0  \n",
       "..       ...   ...    ...  ...  \n",
       "245      0.0   0.0    0.0  0.0  \n",
       "246      0.0   0.0    0.0  0.0  \n",
       "247      0.0   0.0    0.0  0.0  \n",
       "248      0.0   0.0    0.0  0.0  \n",
       "249      0.0   0.0    0.0  0.0  \n",
       "\n",
       "[250 rows x 199 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, use_idf=True)\n",
    "tfidf_vectorized = tfidf_vectorizer.fit_transform(df[\"TitleClean\"])\n",
    "\n",
    "# Use the appropriate method depending on your scikit-learn version\n",
    "try:\n",
    "    feature_names_tfidf = tfidf_vectorizer.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    # Fallback for scikit-learn versions prior to 0.22\n",
    "    feature_names_tfidf = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Create a dataframe with the feature names as columns\n",
    "tfidf_dataframe = pd.DataFrame(tfidf_vectorized.toarray(), columns=feature_names_tfidf)\n",
    "tfidf_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [word_tokenize(clean_text(sentence)) for sentence in df['Title']]\n",
    "model_w2v = Word2Vec(sentences, vector_size=128, window=5, min_count=1)\n",
    "w2v_embeddings = [[model_w2v.wv[word].tolist()for word in sentence] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize all titles with padding and truncation up to a max length\n",
    "# Change `max_length` to the desired sequence length but <= 512\n",
    "encoded_inputs = tokenizer(df[\"TitleClean\"].values.tolist(), padding=True, truncation=True, max_length=tokenizer.model_max_length, return_tensors=\"pt\")\n",
    "\n",
    "encoded_results = model(**encoded_inputs)\n",
    "\n",
    "bert_embeddings = encoded_results.last_hidden_state.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 06:50:47.114361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\"sample sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[-0.03938251,  0.00283756,  0.0224392 ,  0.02451151, -0.04985985,\n",
       "         0.05275183,  0.01906134,  0.03593647, -0.0448441 ,  0.01787178,\n",
       "        -0.0338993 , -0.00872533, -0.02777039,  0.09363514, -0.0239977 ,\n",
       "        -0.08983202, -0.03871281,  0.00450138, -0.02363321, -0.03881206,\n",
       "        -0.01647639,  0.04881011, -0.00920217,  0.05666861, -0.06821937,\n",
       "         0.06926924, -0.01130836, -0.0776007 ,  0.00864497, -0.0289582 ,\n",
       "         0.00346942,  0.01833374, -0.06229272,  0.02653736, -0.09129824,\n",
       "         0.02586212, -0.00045969,  0.03273475, -0.06651255,  0.03915773,\n",
       "        -0.03467301,  0.0575624 , -0.00661325, -0.0138374 , -0.04131497,\n",
       "        -0.02762498,  0.0424963 , -0.00791725,  0.04456054, -0.01393929,\n",
       "        -0.00280851,  0.07165937, -0.03305272,  0.07435055, -0.06612381,\n",
       "        -0.01491496,  0.00656823,  0.04087039,  0.06835364,  0.01885627,\n",
       "        -0.01099553, -0.05027118, -0.02475891,  0.02324308,  0.00917101,\n",
       "         0.00422848,  0.03285244, -0.02794874,  0.06681578,  0.01772704,\n",
       "         0.00811318, -0.01363391,  0.03832594,  0.03436702, -0.01497512,\n",
       "        -0.03681607, -0.08555126,  0.04647087, -0.05387751, -0.05106658,\n",
       "        -0.01240948,  0.01883716, -0.06817443, -0.0272044 ,  0.03788768,\n",
       "         0.08189437, -0.05077631, -0.00592644, -0.07122728, -0.02124343,\n",
       "         0.03251489,  0.08218122, -0.05358632,  0.05782177, -0.03535771,\n",
       "         0.01129865, -0.09399685,  0.05172855,  0.05606828, -0.06419142,\n",
       "        -0.04217637, -0.02035164, -0.06174577, -0.05887276, -0.03922094,\n",
       "        -0.00095737, -0.07074765,  0.06839827, -0.01432929,  0.03085034,\n",
       "        -0.0166887 ,  0.02684403,  0.01011566, -0.01919464, -0.03871478,\n",
       "        -0.04719064, -0.0028155 ,  0.01136836,  0.0757693 , -0.05714425,\n",
       "        -0.05089109,  0.04157005,  0.04282748, -0.06829083,  0.00529   ,\n",
       "         0.06280775, -0.01907049,  0.06616411,  0.05366277,  0.0686838 ,\n",
       "        -0.01309976, -0.02320657,  0.05282814,  0.05526476,  0.04410619,\n",
       "        -0.04601807,  0.03400112,  0.02079639, -0.07758643, -0.01492996,\n",
       "         0.00734602, -0.05957044,  0.06874633,  0.00121153, -0.03040345,\n",
       "         0.00773702,  0.03763071, -0.0266757 ,  0.01105312, -0.01302969,\n",
       "         0.0262951 , -0.04393822, -0.01574445, -0.00013873, -0.01265268,\n",
       "        -0.08327801,  0.00741196, -0.01729107, -0.0266176 ,  0.02400015,\n",
       "         0.0171472 , -0.01485268,  0.01987429, -0.03892666,  0.0293909 ,\n",
       "         0.05969162, -0.0146419 , -0.02844151, -0.01859651,  0.03128742,\n",
       "        -0.04373238,  0.06844956, -0.06656587,  0.02151798, -0.00197275,\n",
       "         0.07032296,  0.08329134,  0.06764324,  0.03775317,  0.05665598,\n",
       "         0.03544157, -0.00635436,  0.05711142,  0.03797805,  0.07851905,\n",
       "         0.04458221,  0.02655105,  0.06770919, -0.02819639, -0.00209855,\n",
       "        -0.00692911,  0.05991054,  0.06608979, -0.02218566,  0.01146971,\n",
       "        -0.06843483,  0.03675382,  0.0216728 ,  0.01118194,  0.02209679,\n",
       "        -0.08551225,  0.02855556,  0.08192262,  0.07225571, -0.02139081,\n",
       "         0.03389956,  0.03287017, -0.05139649, -0.04369969, -0.01681034,\n",
       "        -0.06251386, -0.01821045, -0.02671757,  0.05860669, -0.08143267,\n",
       "         0.00216954,  0.07173088,  0.01494356,  0.06842735,  0.04714647,\n",
       "        -0.04213098,  0.01129522, -0.01849488, -0.00307566, -0.00221626,\n",
       "        -0.06202408,  0.03460697, -0.02811748, -0.01644957, -0.03825342,\n",
       "         0.03133624,  0.06214678,  0.00616974,  0.07309903, -0.01534394,\n",
       "         0.00833383,  0.09190281,  0.00472375,  0.0171463 ,  0.01175478,\n",
       "         0.06811996, -0.00354068,  0.07084652, -0.05632997,  0.04951551,\n",
       "         0.07542304, -0.02672206, -0.0267714 ,  0.09225325,  0.05594753,\n",
       "         0.05164915, -0.07379954, -0.01319662,  0.00844169,  0.09102274,\n",
       "        -0.0933814 , -0.06365124, -0.00512024, -0.04260392, -0.0318252 ,\n",
       "        -0.04653011,  0.07282115,  0.06120919,  0.02762325,  0.02188824,\n",
       "         0.04997718,  0.0565259 , -0.06065087, -0.02432452, -0.04958282,\n",
       "         0.08354066, -0.05786565, -0.06161461,  0.03876181,  0.04536548,\n",
       "        -0.06549892,  0.01718076, -0.02544487,  0.06783323, -0.01492826,\n",
       "        -0.04401976, -0.06317299,  0.02109936,  0.02009708,  0.02694895,\n",
       "        -0.01988646,  0.06725614,  0.07509817, -0.06505589, -0.01058562,\n",
       "         0.00111544, -0.04346174, -0.04704349, -0.02347594, -0.00279038,\n",
       "        -0.05848241,  0.00656353,  0.07698298, -0.04958864,  0.00089596,\n",
       "        -0.03076362,  0.00880422, -0.00984702, -0.0666048 , -0.03217181,\n",
       "         0.00737464,  0.00743698, -0.04848077, -0.04599656, -0.01658653,\n",
       "         0.03719768,  0.03567538, -0.02642647, -0.0560194 ,  0.02118313,\n",
       "         0.01857023,  0.03219406,  0.00256123,  0.0421124 ,  0.00180314,\n",
       "        -0.03621173, -0.01979278,  0.03405035,  0.06373078, -0.05494245,\n",
       "        -0.02396549, -0.03126418,  0.04528202, -0.01358993, -0.06309366,\n",
       "         0.01178989,  0.00344057, -0.00787313, -0.02162974,  0.05335506,\n",
       "         0.02862112, -0.04302215,  0.03279804,  0.05158651, -0.00285277,\n",
       "         0.05304098,  0.04128712,  0.05630501, -0.0077656 , -0.05273559,\n",
       "        -0.05585646,  0.06580391,  0.04389298, -0.07738475,  0.05392035,\n",
       "        -0.00390925, -0.02636706,  0.06761489, -0.06527744,  0.00472483,\n",
       "        -0.04030437, -0.0846021 , -0.0422632 , -0.00158288, -0.05391552,\n",
       "        -0.0365828 ,  0.02166616, -0.06437152, -0.05959262,  0.04433994,\n",
       "        -0.01927058,  0.00990551, -0.01328873,  0.05027935, -0.04969057,\n",
       "        -0.00987442, -0.0113115 ,  0.00374613,  0.06166527, -0.00958102,\n",
       "         0.05171459, -0.07116563,  0.01393948, -0.06607787, -0.02151019,\n",
       "        -0.03134883, -0.07351542, -0.04622084, -0.00069518,  0.05323111,\n",
       "        -0.03160188, -0.01201572, -0.01656733, -0.07507901,  0.04848735,\n",
       "        -0.03386586,  0.02609415,  0.03240789, -0.03152505, -0.00563664,\n",
       "        -0.03389145, -0.04247319, -0.06651931,  0.01189627, -0.08983452,\n",
       "        -0.07792971,  0.02540242,  0.02835975,  0.0381611 , -0.04952798,\n",
       "        -0.02318211,  0.01381743, -0.02686516,  0.02689179,  0.0609198 ,\n",
       "        -0.00534935, -0.03062114,  0.07490493, -0.06924382,  0.06250685,\n",
       "         0.0117653 ,  0.05324204,  0.04759085, -0.00964118, -0.06132188,\n",
       "        -0.01176929, -0.03799563,  0.03033183, -0.04196732, -0.01469689,\n",
       "        -0.01645245,  0.03142982,  0.03658862, -0.02304139,  0.05155923,\n",
       "        -0.03684806, -0.02431933,  0.0252458 ,  0.01962425,  0.04557411,\n",
       "        -0.03478403,  0.02497469,  0.04358508,  0.02545021,  0.02375783,\n",
       "         0.02418486, -0.04044397,  0.02420264, -0.01500762,  0.0481863 ,\n",
       "         0.02245378, -0.00318866, -0.06289262,  0.02846058,  0.03304677,\n",
       "         0.01235784, -0.02892571, -0.03213081, -0.05937484, -0.00706264,\n",
       "         0.04065439,  0.00428566,  0.07599301,  0.01902851,  0.02006776,\n",
       "         0.03920979,  0.01203545, -0.03457658,  0.00947897,  0.02689039,\n",
       "        -0.09302811, -0.05073654,  0.06594383, -0.03593604,  0.08359373,\n",
       "        -0.03627726,  0.04771991, -0.00681499, -0.08518136,  0.03438934,\n",
       "         0.00634363,  0.00732988,  0.02077879,  0.02404722, -0.00501698,\n",
       "         0.05448833, -0.0301137 ,  0.02906741, -0.02578296, -0.04801914,\n",
       "        -0.07785395, -0.09244819,  0.01018278,  0.01269109,  0.03765409,\n",
       "         0.00351432, -0.04050643, -0.05167732, -0.00377256, -0.0288763 ,\n",
       "         0.05255816, -0.03409978, -0.07004246,  0.00485595,  0.00034773,\n",
       "         0.0798631 , -0.02423762, -0.05401813, -0.08589488,  0.08340829,\n",
       "        -0.00943786,  0.00120672, -0.05931319,  0.04025966, -0.05952222,\n",
       "        -0.0371703 ,  0.01036991]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "high_dim_data = tfidf_vectorized\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, init=\"random\")\n",
    "reduced_data_tsne = tsne.fit_transform(high_dim_data)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(reduced_data_tsne[:, 0], reduced_data_tsne[:, 1])\n",
    "plt.title('2D t-SNE of High-Dimensional Data')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "reduced_data_umap = reducer.fit_transform(high_dim_data)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(reduced_data_umap[:, 0], reduced_data_umap[:, 1])\n",
    "plt.title('2D UMAP of High-Dimensional Data')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Assuming `X` is your feature matrix and `y` is your target labels\n",
    "#lda = LDA(n_components=2)\n",
    "#X_lda = lda.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming `high_dim_data` is your high-dimensional data\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data_pca = pca.fit_transform(high_dim_data)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(reduced_data_pca[:, 0], reduced_data_pca[:, 1])\n",
    "plt.title('2D PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
